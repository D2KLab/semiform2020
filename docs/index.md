---
title: About
layout: default

navigation_weight: 1
---

# Abstract

In the age of post-truth, misinformation has become too dangerously common, and is actively and successfully influencing public perception and stance towards many sensitive issues and domains, including economy, health, environment, culture, and foreign policy. Today, around half the world’s population have access to the Internet, where they can create, propagate, and consume information instantly and globally. In spite of this rising addiction to rapid consumption of online information, people and current technologies are yet to adapt to the age of misinformation, where incorrect or misleading information is intentionally or unintentionally spread across all media, and in particular across the Web and social media. This workshop aims to gather cutting edge research, expertise, and techniques generated by the Semantic Web community, to join the emerging global battle against misinformation.

# Motivation

Digital misinformation is becoming pervasive in all online media to the extent that it has been listed by the World Economic Forum as one of the main threats to our society, by generating various technological and geopolitical risks ranging from terrorism to cyber attacks and the failure of global governance. In particular, there is evidence that misinformation has been affecting our perceptions in critical domains, such as health, politics, foreign policy, economy, and environment. Indeed, disinformation was found to pose high risks to society, by accelerating extremism, hysteria, and herding behaviour.
In spite of the rising addiction to rapid consumption of online news information, people and current technologies are yet to adapt to the age of misinformation. As a recent European Parliament report states, there is an urgent need to develop a new generation of content verification and misinformation analysis and tracking tools.

Some technologies have been developed to help validating different types of content (images, videos, bot accounts, news sources, reviews, etc.). Examples include [NewsGuard](www.newsguardtech.com), [B.S.Detector](https://gitlab.com/bs-detector/bs-detector), [ClaimBuster](https://idir.uta.edu/claimbuster/), [TinEye.com](https://tineye.com/), and [Rbutr.com](http://rbutr.com/). Others focused on developing techniques for automatically identifying fake news, rumour posts, disputed arguments, measuring posts’ credibility, validating specific claims, or tracking the spread of disinformation. These technologies often use standard machine learning techniques, with little to no use of semantic techniques and representations.

Although disinformation is a common problem in all media, it is exacerbated in digital social media due to the speed and ease in which they are spread. The social web enables people to spread information rapidly without confirmation of truth, and to paraphrase this information to fit their intentions and preset beliefs. This phenomena is affecting society at all levels, including citizens, communities, journalists, and policymakers. Recent studies showed that fake news spread far more virally than real news; sometimes thousands of times more. As a result, social media platforms have been put under heavy criticism and pressure to tackle the spread of misinformation, disinformation, and fake news on their platforms. However, these platforms are yet to offer adequate social and technical solutions to this problem, and are unlikely to do so for various economic, technical, and ethical reasons.

On another front, more than 188 independent fact-checking groups and organisations emerged online in over 60 countries over the past decade, with an increase of 26% in the last year alone, and 61 of them are in Europe. These organisations provide independent professional fact checking to the public on various current news and information, and many of them publish their fact checks using the schema.org ClaimReview semantic standard. However, simply publishing corrective information by fact checkers is often regarded as insufficient for changing misinformed beliefs and opinions.

To this end, Semantics could offer major contributions to these efforts, in detecting misinformation content, monitoring its spread and impact, predicting its evolution, identifying misinforming sources, and locating relevant fact checking articles, relying on background knowledge graphs with adequate references such as Wikidata. Misinformation is a major societal challenge, and it is time for the Semantic Web researchers and practitioners to join their efforts to tackle this challenge.   

# Topics of interest

Includes but not limited to:
- Ontologies for representing rumors, misinformation, disinformation, and other deceptive content
- Semantic models of misinformation detection
- Knowledge graphs for integrating and analysing misinformation content
- Semantic analysis of opinion and sentiment towards misinformation
- Misinformed-behaviour semantic representation and analysis
- Detection of information and semantic frame manipulation
- Semantic similarity of articles with more/less exaggerated/biased content
- Semantic topic affinity analysis of users sharing unreliable content
- Semantic extraction of misinforming topics and events
- Misinformation semantic patterns identification and prediction
- Semantically-enriched datasets of misinformation content and sources
- Semantic matching of Fact-Checking misinformation assessment labels
- Modelling user/information source trustworthiness
- Semantic annotation standards for misinformation annotation
- ClaimReview schema usage and structure assessment
- Semantic applications for tackling the spread of misinformation
- Using Linked Open Data as a source of factual information


# Workshop Format

SEMIFORM will be a half-day workshop and will consist of (a) invited talks, one from academia, and one from a fact-checking organisation, (b) peer-reviewed short papers (up to 4 pages long) and long papers (up to 8 pages long), (c) poster and demo session, and a (d) panel and discussion session. Accepted papers will have the chance to be included in the Journal of Semantic Web special issue on Web Content Credibility.

# Community

Research on misinformation has been increasing in recent years, with papers emerging in a vast number of conferences, including ISWC, ESWC, The Web Conf., IJCAI, to name just a few, and journals such as Semantic Web Journal, PLOS ONE and PNAS. Workshops that tackle the general research and analysis of misinformation have been organised recently, such as RumourEval 2019, ICWSM Digital Misinformation 2017, ESWC KNOW 2020 and RDSM 2020. Through our SEMIFORM workshop, we aim to raise the topic of misinformation in ISWC -- the flagship conference of the semantic web community -- and to bring together researchers from a complementary range of disciplines, including semantic knowledge graphs, network analysis, social semantics, social data science, web science, and natural language processing.

Examples of recent external relevant publications:
1. Fernandez, Miriam and Alani, Harith (2018). **Online Misinformation: Challenges and Future Directions**. In: _WWW'18 Companion: The 2018 Web Conference Companion_, ACM, New York, pp. 595–602.
1. Mensio, Martino and Alani, Harith (2019). **News Source Credibility in the Eyes of Different Assessors**. In: _Conference for Truth and Trust Online_, 4-5 Oct 2019, London, UK.
1. Mensio, Martino and Alani, Harith (2019). **MisinfoMe: Who’s Interacting with Misinformation?** In: _18th International Semantic Web Conference (ISWC 2019): Posters & Demonstrations, Industry and Outrageous Ideas Tracks_, 26-30 Oct 2019, Auckland, New Zeeland, CEUR WS.
1. Farrell, Tracie; Piccolo, Lara; Perfumi, Serena Coppolino and Alani, Harith (2019). **Understanding the Role of Human Values in the Spread of Misinformation**. In: _Conference for Truth and Trust Online._
1. A Aker, A Sliwa, F Dalvi,  K Bontcheva. **Rumour verification through recurring information and an inner-attention mechanism.** In: _Online Social Networks and Media_, 2019
1. M Lukasik, K Bontcheva, T Cohn, A Zubiaga, M Liakata. **Gaussian processes for rumour stance classification in social media.** In: _ACM Transactions on Information Systems (TOIS)_, 2019
1. JZ Pan, S Pavlova, C Li, N Li, Y Li, J Liu. **Content based fake news detection using knowledge graphs** In: _International Semantic Web Conference (ISWC)_, 2018
1. Tchechmedjiev A., Pavlos Fafalios, Katarina Boland, Malo Gasquet, Matthäus Zloch, Benjamin Zapilko, Stefan Dietze, Konstantin Todorov. **ClaimsKG: A Knowledge Graph of Fact-Checked Claims**. In: _International Semantic Web Conference (ISWC)_, 2019.
